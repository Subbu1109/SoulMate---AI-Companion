# ğŸ’ SoulMate.AGI â€“ Your Emotional Wellness Companion

## ğŸ“Œ Description

**SoulMate.AGI** is a comprehensive AI-powered mental wellness assistant that blends **emotion detection**, **interactive chat**, **multi-lingual voice input**, **personal journaling with sentiment scoring**, and **analytics**â€”all into a seamless web experience.

Whether you're feeling overwhelmed, joyful, or reflective, SoulMate.AGI listens, understands, and supports you with intelligent features driven by computer vision, NLP, and speech recognition.

---

## ğŸ¯ Purpose

Mental health challenges are growing, and access to personalized, empathetic care remains limited. SoulMate.AGI aims to:
- ğŸ‘€ **Understand their emotions** in real time
- ğŸ—£ï¸ **Talk to an emotional support companion**
- ğŸ““ **Reflect on daily feelings via a sentiment diary**
- ğŸ¤ **Use multi-lingual voice input to journal hands-free**
- ğŸŒ **Experience multilingual emotional tracking**
- ğŸ“Š **View emotional trends with analytics**
- ğŸ§˜â€â™€ï¸ **Provide breathing exercises, daily wellness tips, guided relaxation sessions, and yoga content for inner balance**

---

## ğŸ—‚ï¸ Project Directory Structure

```bash
SOULMATE/
â”‚
â”œâ”€â”€ backend/                    # Flask backend server
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ chatbot/                    # AI mental health chat logic
â”‚   â””â”€â”€ chat.py
â”‚
â”œâ”€â”€ emotion_detection/         # CNN emotion detection model
â”‚   â”œâ”€â”€ emotion_model.h5
â”‚   â”œâ”€â”€ emotion_detection_cam.py
â”‚   â”œâ”€â”€ test_camera.py
â”‚   â””â”€â”€ *.jpg (sample training images)
â”‚
â”œâ”€â”€ speech_text/               # Speech-to-text using google translate
â”‚   â””â”€â”€ speech_wo_auto.py
â”‚
â”œâ”€â”€ frontend/                  # Next.js + Tailwind frontend
â”‚   â”œâ”€â”€ about/
â”‚   â”œâ”€â”€ analytics/
â”‚   â”œâ”€â”€ chat/
â”‚   â”œâ”€â”€ diary/
â”‚   â”œâ”€â”€ wellness/
â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”œâ”€â”€ page.tsx
â”‚   â”œâ”€â”€ globals.css
â”‚   â””â”€â”€ components/
â”‚
â”œâ”€â”€ venv/                      # Python virtual environment
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ speech_to_text.py          # Standalone speech module
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LISENCE
â””â”€â”€ README.md
```

---

## Steps to Execute the Project

### 1. Setup Environment

a. **Create a virtual environment:**

```bash
python -m venv venv
```

b. **Activate your virtual environment:**

- **Windows:**
```bash
.venv\Scripts\activate
```

---

### 2. Install Dependencies

c. **Install from `requirements.txt`:**

```bash
pip install -r requirements.txt
```

---
## Execute the plug-ins (Chatbot, Camera, Voice-to-text) individually to check their performance

a. **Run Chatbot:**

```bash
python chatbot/chat.py
```

b. **Run Emotional Detection Camera:**

1. **Test Camera**

```bash
python emotion_detection/test_camera.py
```

2. **Execute emotional detection camera**

```bash
python emotion_detection/emotion_detection_cam.py
```

c. **Run Multi-lingual voice to text:**

1. **Multi-lingual voice to text using google translate API**

```bash
python speech_text/speech_wo_auto.py
```

2. **Multi-lingual voice to text using googletrans library**

```bash
python speech_to_text.py
```

---

## Backend Execution Steps

a. **Run Flask backend server:**

```bash
python backend/main.py
```

---

## Frontend Execution Steps

a. **Install frontend dependencies:**

```bash
npm install 
```

b. **Fix vulnerabilities (optional but recommended):**

```bash
npm audit fix
```

c. **Run the React frontend:**

```bash
npm run dev
```

---
